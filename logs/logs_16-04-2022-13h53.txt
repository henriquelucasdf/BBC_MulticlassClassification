INFO:root:   A new run has started with the arguments: Namespace(best_model_metric='balanced_accuracy', cv_splits=5, data_relative_path='data/', random_state=1, verbose=2)
INFO:root:   The defined preprocess steps are:   [('text_proc', CustomTextPreprocessor()), ('tfidf', TfidfVectorizer(max_df=0.95, max_features=5000, min_df=2)), ('svd', TruncatedSVD(n_components=1000, n_iter=30, random_state=1))]
INFO:root:   The defined models to test are:   [('LogReg', LogisticRegression(n_jobs=-1, random_state=1)), ('RandomForest', RandomForestClassifier(max_depth=7, n_estimators=1000, n_jobs=-1,
                       random_state=1)), ('LightGBM', LGBMClassifier(learning_rate=0.05, max_depth=5, n_estimators=500,
               random_state=1))]
INFO:root:    Starting the cross-validation of the model LogReg...
INFO:root:    Finishing the cross-validation of the model LogReg after 53.54 seconds...
INFO:root:    LogReg - Mean CV Results: {'balanced_accuracy': 0.982, 'f1_macro': 0.982, 'precision_macro': 0.982, 'recall_macro': 0.982}
INFO:root:    Starting the cross-validation of the model RandomForest...
INFO:root:    Finishing the cross-validation of the model RandomForest after 65.35 seconds...
INFO:root:    RandomForest - Mean CV Results: {'balanced_accuracy': 0.96, 'f1_macro': 0.961, 'precision_macro': 0.963, 'recall_macro': 0.96}
INFO:root:    Starting the cross-validation of the model LightGBM...
INFO:root:    Finishing the cross-validation of the model LightGBM after 118.56 seconds...
INFO:root:    LightGBM - Mean CV Results: {'balanced_accuracy': 0.975, 'f1_macro': 0.974, 'precision_macro': 0.974, 'recall_macro': 0.975}
INFO:root:    Getting the best model by the metric balanced_accuracy
INFO:root:    Best model found: LogReg
INFO:root:    Starting the hyperparameters optimization...
INFO:root:    The possible hyperparameters are: {'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2)], 'tfidf__max_df': [0.9, 0.95, 0.99], 'tfidf__min_df': [1, 3, 5], 'tfidf__max_features': [3000, 5000, 7500, 10000], 'svd__n_components': [500, 750, 1000], 'svd__n_iter': [30, 50, 75], 'LogReg__C': [0.1, 1, 10, 100], 'LogReg__class_weight': [None, 'balanced'], 'LogReg__penalty': ['none', 'l2'], 'LogReg__max_iter': [100, 200, 300]}
INFO:root:    The best parameters found were: {'tfidf__ngram_range': (1, 1), 'tfidf__min_df': 3, 'tfidf__max_features': 7500, 'tfidf__max_df': 0.95, 'svd__n_iter': 75, 'svd__n_components': 1000, 'LogReg__penalty': 'none', 'LogReg__max_iter': 200, 'LogReg__class_weight': 'balanced', 'LogReg__C': 10}
INFO:root:    The best metric (balanced_accuracy) was: 0.9833518206449908
INFO:root:    Saving the best estimator on the folder 'models'...
INFO:root:    The model was saved in the filepath /mnt/d/repos/estudos/formacao_MLENG/ML_Python_C++/BBC_MulticlassClassification/models/best_pipeline_16-04-2022-14h16.pkl
INFO:root:    Finalizing the script...
